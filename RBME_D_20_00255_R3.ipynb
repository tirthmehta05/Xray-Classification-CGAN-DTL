{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Introduction</h3>\n",
        "\n",
        "The manuscript \"**[Classification of X-ray images into COVID-19, pneumonia, and TB using cGAN and fine-tuned deep transfer learning models](https://link.springer.com/article/10.1007/s42600-021-00174-z)**\" presents a novel approach to classifying chest X-ray images into three categories: COVID-19, pneumonia, and tuberculosis (TB). The study combines conditional Generative Adversarial Networks (cGAN) with fine-tuned deep transfer learning models to improve the accuracy and reliability of the classification process.\n",
        "\n",
        "Hereâ€™s a brief overview of the methodology and findings from the study:\n",
        "<ul>\n",
        "<li>Conditional GAN (cGAN): The cGAN is used to generate synthetic X-ray images that can augment the training dataset, addressing the issue of limited labeled data.</li>\n",
        "\n",
        "<li>Deep Transfer Learning Models: The research leverages pre-trained deep learning models fine-tuned on the augmented dataset. This helps in transferring learned features from large datasets to the specific task of X-ray image classification.</li>\n",
        "\n",
        "<li>Classification Performance: The proposed method demonstrates high accuracy in distinguishing between COVID-19, pneumonia, and TB. This hybrid approach aims to overcome common challenges in medical image classification, such as data scarcity and class imbalance.</li>\n",
        "\n",
        "<li>Practical Implications: The approach offers a promising tool for aiding in the rapid and accurate diagnosis of these respiratory conditions, which is crucial in clinical settings, especially during pandemics like COVID-19.</li>"
      ],
      "metadata": {
        "id": "WP_OmQ95_8Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Code for Conditional Generative Adversarial Networks cGAN</h3>"
      ],
      "metadata": {
        "id": "jACCXJfAAq9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.fashion_mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Concatenate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "jwsI_8JmFNvj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d6f6dc3c-606c-4f0d-ac71-162b3d5c7068"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.utils.vis_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-08054605ac5a>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.vis_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_discriminator(in_shape=(224,224,3), n_classes=6):\n",
        "  in_label = Input(shape=(1,))\n",
        "  li = Embedding(n_classes, 50)(in_label)\n",
        "  n_nodes = in_shape[0] * in_shape[1]\n",
        "  li = Dense(n_nodes)(li)\n",
        "  li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
        "  in_image = Input(shape=in_shape)\n",
        "  merge = Concatenate()([in_image, li])\n",
        "  fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Flatten()(fe)\n",
        "  fe = Dropout(0.4)(fe)\n",
        "  out_layer = Dense(1, activation='sigmoid')(fe)\n",
        "  model = Model([in_image, in_label], out_layer)\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def define_generator(latent_dim, n_classes=6):\n",
        "  in_label = Input(shape=(1,))\n",
        "  li = Embedding(n_classes, 50)(in_label)\n",
        "  n_nodes = 56*56\n",
        "  li = Dense(n_nodes)(li)\n",
        "  li = Reshape((56, 56, 1))(li)\n",
        "  in_lat = Input(shape=(latent_dim,))\n",
        "  n_nodes = 128* 56 * 56\n",
        "  gen = Dense(n_nodes)(in_lat)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "  gen = Reshape((56, 56, 128))(gen)\n",
        "  merge = Concatenate()([gen, li])\n",
        "  gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "  gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "  out_layer = Conv2D(3, (7,7), activation='tanh', padding='same') (gen)\n",
        "  model = Model([in_lat, in_label], out_layer)\n",
        "  return model\n",
        "\n",
        "def define_gan(g_model, d_model):\n",
        "  d_model.trainable = False\n",
        "  gen_noise, gen_label = g_model.input\n",
        "  gen_output = g_model.output\n",
        "  gan_output = d_model([gen_output, gen_label])\n",
        "  model = Model([gen_noise, gen_label], gan_output)\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "  return model\n",
        "\n",
        "def scale(X):\n",
        "  X = X.astype('float32')\n",
        "  X = (X - 127.5) / 127.5\n",
        "  return X\n",
        "\n",
        "def load_real_samples():\n",
        "  TRAINING_DIR = \"Path to images\"\n",
        "  train_image_generator = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "  train_generator = train_image_generator.flow_from_directory(TRAINING_DIR,target_size=(224,224),class_mode='categorical',batch_size=32)\n",
        "  return train_generator\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "  n = len(dataset[0][0])\n",
        "  labels =dataset[0][1]\n",
        "  label = []\n",
        "  for i in range(n): label.append(np.argmax(labels[i]))\n",
        "  label = np.reshape(label,(n,1))\n",
        "  dataset = dataset[0][0]\n",
        "  ix = randint(0, n, n_samples)\n",
        "  X = dataset[ix]\n",
        "  y = ones((n_samples, 1))\n",
        "  return [X, label], y\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=6):\n",
        "  x_input = randn(latent_dim * n_samples)\n",
        "  z_input = x_input.reshape(n_samples, latent_dim)\n",
        "  labels = randint(0, n_classes, n_samples)\n",
        "  return [z_input, labels]\n",
        "\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "  images = generator.predict([z_input, labels_input])\n",
        "  y = zeros((n_samples, 1))\n",
        "  return [images, labels_input], y\n",
        "\n",
        "def save_plot(examples, epoch, n=5):\n",
        "  print(examples.shape)\n",
        "  examples = (examples + 1) / 2.0\n",
        "  for i in range(n * n):\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(examples[i])\n",
        "  filename = 'path to store output image/generate d_plot_e%03d.png' % (epoch+1)\n",
        "  pyplot.savefig(filename)\n",
        "  pyplot.close()\n",
        "\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=32):\n",
        "  [X_real,labels_real], y_real = generate_real_samples(dataset, n_samples)\n",
        "  [x_fake,labels], y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "  save_plot(x_fake, epoch)\n",
        "  filename = 'path to store output image/generate r_model_%03d.h5' % (epoch+1)\n",
        "  g_model.save(filename)\n",
        "\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=32):\n",
        "  bat_per_epo = int(dataset.samples / n_batch)\n",
        "  half_batch = int(n_batch)\n",
        "  for i in range(n_epochs):\n",
        "    for j in range(bat_per_epo):\n",
        "      [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
        "      d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
        "      [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "      d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
        "      [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
        "      y_gan = ones((n_batch, 1))\n",
        "      g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
        "      print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "    if (i+1) % 10 == 0:\n",
        "      summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
        "  g_model.save('path to save model')"
      ],
      "metadata": {
        "id": "DSspYkOIAvCt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_2ySlfm_UeZ"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100\n",
        "d_model = define_discriminator()\n",
        "g_model = define_generator(latent_dim)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "dataset = load_real_samples()\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import asarray\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "xBZdEQj3FuTP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_points(latent_dim, n_samples, n_classes=6):\n",
        "  x_input = randn(latent_dim * n_samples)\n",
        "  z_input = x_input.reshape(n_samples, latent_dim)\n",
        "  labels = randint(0, n_classes, n_samples)\n",
        "  return [z_input, labels]\n",
        "\n",
        "def save_plot(examples, n):\n",
        "  print(examples.shape)\n",
        "  \"\"\"for i in range(100):pyplot.axis(\"off\") pyplot.imshow(examples[i],cmap=\"gray\")\n",
        "  filename = '/content/drive/My Drive/X-Ray_folders/6- Class/output/train/NORMAL/genereated_image_%03d' % (i+1)\n",
        "  pyplot.savefig(filename) pyplot.close()\"\"\"\n",
        "  for i in range(n * n):\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(examples[i],cmap=\"gray\")\n",
        "  filename ='generated_image_000'\n",
        "  pyplot.savefig(filename)\n",
        "  pyplot.show()"
      ],
      "metadata": {
        "id": "d9BaQfN9_706"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('path to model/cgan_generator.h5',compile=False)\n",
        "latent_points, labels = generate_latent_points(100,100)\n",
        "labels = np.array([2]*100)\n",
        "X = model.predict([latent_points, labels])\n",
        "X = (X + 1) / 2.0\n",
        "save_plot(X, 6)"
      ],
      "metadata": {
        "id": "i6oRyGfsGOZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Code for Deep Transfer Learning Model - ResNet-50 </h3>"
      ],
      "metadata": {
        "id": "5yLYl3BIHN9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "print (tf. version )\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "%matplotlib inline\n",
        "import cv2"
      ],
      "metadata": {
        "id": "SpwApATRHxy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3feded2-1d49-42d6-edc5-c9522d9af335"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = 'path to training dataset'\n",
        "TEST_DIR = 'path to testing dataset'\n",
        "VAL_DIR = 'path to validation dataset'\n",
        "classes = [\"COVID-MEDIUM\",\"COVID-MILD\",\"COVID- SEVERE\",\"NORMAL\",\"PNEUMONIA\",\"TB\"]\n",
        "INIT_LR = 1e-1\n",
        "BS = 8\n",
        "EPOCHS = 12\n",
        "\n",
        "training_size = 0\n",
        "test_size = 0\n",
        "val_size = 0\n",
        "for i in classes:\n",
        "  training_size += len(glob(TRAINING_DIR+\"/\"+i+\"/*\"))\n",
        "  test_size += len(glob(TEST_DIR+\"/\"+i+\"/*\"))\n",
        "  val_size += len(glob(VAL_DIR+\"/\"+i+\"/*\"))\n",
        "print(training_size,test_size,val_size)\n",
        "COVID_MED_DIR = 'path to training dataset/COVID-MEDIUM'\n",
        "COVID_MILD_DIR = 'path to training dataset/COVID-MILD'\n",
        "COVID_SEVERE_DIR = 'path to training dataset/6- Class/COVID-SEVERE'\n",
        "NORMAL_DIR = 'path to training dataset/6- Class/NORMAL'\n",
        "PNEUMONIA_DIR = 'path to training dataset/6- Class/PNEUMONIA'\n",
        "TB_DIR = 'path to training dataset/6-Class/TB'\n",
        "\n",
        "\n",
        "covid_med_c = len(glob(COVID_MED_DIR+\"/*\")) + 100\n",
        "covid_mild_c = len(glob(COVID_MILD_DIR+\"/*\")) + 100\n",
        "covid_severe_c = len(glob(COVID_SEVERE_DIR+\"/*\")) + 100\n",
        "normal_c = len(glob(NORMAL_DIR+\"/*\"))\n",
        "pneumonia_c = len(glob(PNEUMONIA_DIR+\"/*\"))\n",
        "tb_c = len(glob(TB_DIR+\"/*\"))\n",
        "class_weight = [covid_med_c,covid_mild_c,covid_severe_c,normal_c, pneumonia_c,tb_c]\n",
        "print(class_weight)\n",
        "\n",
        "x = max(class_weight)\n",
        "for i in range(0,len(class_weight)):\n",
        "  class_weight[i] = round(x/class_weight[i],2)\n",
        "print(class_weight)\n",
        "class_weights = {}\n",
        "for i in range(0,len(class_weight)):\n",
        "  class_weights[i] = class_weight[i]\n",
        "print(class_weights)\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale = 1.0/255.)\n",
        "validation_image_generator = ImageDataGenerator(rescale = 1.0/255.)\n",
        "train_generator = train_image_generator.flow_from_directory(TRAINING_DIR,target_size=(224,224),class_mode='categorical')\n",
        "valid_generator = validation_image_generator.flow_from_directory( VAL_DIR,target_size=(224,224),class_mode=\"categorical\")\n",
        "test_generator = validation_image_generator.flow_from_directory(TEST_DIR,target_size=(224,224),class_mode=\"categorical\")\n",
        "labels = (test_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "print(\"labels \", labels)\n",
        "sample_training_data,sample_training_label = next(train_generator)\n",
        "\n",
        "def plotImages(images_arr):\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images_arr, axes):\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "plotImages(sample_training_data[:5])\n",
        "print(sample_training_label[:5])\n",
        "\n",
        "base_model = keras.applications.ResNet50(weights=\"imagenet\",include_top=False,input_shape=(224,224,3),pooling='avg')\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "base_model.summary()\n",
        "model = keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(keras.layers.Dense(6, activation = \"softmax\"))\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=INIT_LR),loss=\"categorical_crossentropy\", metrics= [\"accuracy\"])\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "history = model.fit(train_generator, validation_data=valid_generator, epochs=EPOCHS,callbacks = [early_stopping_cb,tensorboard_cb],class_weight=class_weights)\n",
        "model.save(\"path to save model/DW6CLASSRESNET50.h5\")\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs = len(history.epoch)\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "baseline_results = model.evaluate(test_generator, batch_size=BS, verbose=0)\n",
        "for name, value in zip(model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "\n",
        "nrows = 3\n",
        "ncols = 4\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "num_predictions = 12\n",
        "testData,testLabels = next(test_generator)\n",
        "test_indices = np.random.choice(np.arange(0, len(testLabels)), size=(num_predictions,))\n",
        "test_images = np.stack(([testData[i] for i in test_indices]))\n",
        "test_labels = np.stack(([testLabels[i] for i in test_indices]))\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "print(np.argmax(predictions[0]))\n",
        "\n",
        "\n",
        "for i in range(num_predictions):\n",
        "  prediction = np.argmax(predictions[i])\n",
        "  test_label = np.argmax(test_labels[i])\n",
        "  image = (test_images[i] * 255).astype(\"uint8\")\n",
        "  if prediction == test_label:\n",
        "    rgb_color = (0, 255, 0)\n",
        "  else:\n",
        "    rgb_color = (255, 0, 0)\n",
        "\n",
        "  cv2.putText(image, str(labels[prediction]), (0, 18),cv2.FONT_HERSHEY_SIMPLEX,0.75,rgb_color, 1)\n",
        "\n",
        "  sp = plt.subplot(nrows, ncols, i + 1, title=\"label: %s\" % test_labels[i])\n",
        "  sp.axis('Off')\n",
        "  plt.imshow(image)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fWdPsSscHfeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4> Similar to the ResNet-50 you can use the same implementation with minute changes to run other models like ResNet-101, Xception, DenseNet-169, DenseNet201. </h4>"
      ],
      "metadata": {
        "id": "gFyDPlFXZOH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Code for Lung Segmentation </h3>"
      ],
      "metadata": {
        "id": "iMeMelqOZvxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from cv2 import imread, createCLAHE\n",
        "import cv2\n",
        "from glob import glob\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateSchedule r"
      ],
      "metadata": {
        "id": "6IlkzM9OaW1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "  y_true_f = keras.flatten(y_true)\n",
        "  y_pred_f = keras.flatten(y_pred)\n",
        "  intersection = keras.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred): return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def unet(input_size=(256,256,1)):\n",
        "  inputs = Input(input_size)\n",
        "\n",
        "  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same') (inputs)\n",
        "  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same') (conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "  conv2 = Conv2D(64, (3, 3), activation='relu', padding='same') (pool1)\n",
        "  conv2 = Conv2D(64, (3, 3), activation='relu', padding='same') (conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "  conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "\n",
        "  conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "  conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "  up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "  conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "  conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "  up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "  conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "  conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "  up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "  conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "  conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "  up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "  conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "  conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "  conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "  return Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "\n",
        "model = unet(input_size=(512,512,1))\n",
        "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef, 'binary_accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.load_weights(\"path to model folder/6- Class/cxr_reg_weights.best.hdf5\")\n",
        "\n",
        "import keras\n",
        "TRAINING_DIR = '/content/drive/MyDrive/X-Ray_folders/6- Class/output/train'\n",
        "TEST_DIR = '/content/drive/MyDrive/X-Ray_folders/6- Class/output/test'\n",
        "VAL_DIR = '/content/drive/MyDrive/X-Ray_folders/6- Class/output/val'\n",
        "\n",
        "arr = [\"COVID-MEDIUM\",\"COVID-MILD\",\"COVID- SEVERE\",\"NORMAL\",\"PNEUMONIA\",\"TB\"]\n",
        "\n",
        "for a in arr:\n",
        "  print(TEST_DIR+\"/\"+a+\"/\")\n",
        "  files=glob(TEST_DIR+\"/\"+a+\"/\"+\"*\")\n",
        "  c = 0\n",
        "  for j in files:\n",
        "    image = tf.keras.preprocessing.image.load_img(j,target_size=( 512,512),color_mode=\"grayscale\")\n",
        "    input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "    input_arr = input_arr/255\n",
        "    input_arr = np.array([input_arr])\n",
        "    prediction = model.predict(input_arr)\n",
        "    plt.show()\n",
        "    res = np.squeeze(prediction)\n",
        "    (h,w) = res.shape\n",
        "    color = np.array([[[255]*(3)]*(w)]*h)\n",
        "    image = tf.keras.preprocessing.image.load_img(j,target_size=(512,512))\n",
        "    image = keras.preprocessing.image.img_to_array(image)\n",
        "    for i in range(h-1):\n",
        "      for j in range(w-1):\n",
        "        if(round(res[i][j])==1):\n",
        "          for k in range(3):\n",
        "            color[i][j][k] = image[i][j][k]\n",
        "        elif(round(res[i][j])==0):\n",
        "          for k in range(3):\n",
        "            color[i][j][k] = round(res[i][j])\n",
        "    c+=1\n",
        "  cv2.imwrite(\"path to output folder/6- Class/output1/test/\"+a+\"/\"+str(c)+\".jpg\",color)"
      ],
      "metadata": {
        "id": "rZoBaVEnZtjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Supplementary Information](https://www.editorialmanager.com/rbme/download.aspx?id=14019&guid=aea56d1c-3f99-4b8f-8c60-74c9b6d7f790&scheme=1)"
      ],
      "metadata": {
        "id": "fFeMHZBlr-bx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hDQA9M6UsD5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}